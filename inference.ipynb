{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f156b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "device = \"cpu\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2790ec",
   "metadata": {},
   "source": [
    "### model architecture should be same as training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bbca6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebertaHierarchicalClassifier(nn.Module):\n",
    "    def __init__(self, encoder, num_lob, num_cov):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        hidden_size = encoder.config.hidden_size\n",
    "        self.lob_head = nn.Linear(hidden_size, num_lob)\n",
    "        self.coverage_head = nn.Linear(hidden_size, num_cov)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        pooled = outputs.last_hidden_state[:, 0]  # CLS token\n",
    "\n",
    "        lob_logits = self.lob_head(pooled)\n",
    "        coverage_logits = self.coverage_head(pooled)\n",
    "\n",
    "        return lob_logits, coverage_logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37824ebe",
   "metadata": {},
   "source": [
    "### loading the tokenizer,encoder,labels from the saved folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e39b8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"model_artifacts1\"\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"{BASE_DIR}/tokenizer\")\n",
    "\n",
    "# Encoder\n",
    "encoder = AutoModel.from_pretrained(f\"{BASE_DIR}/model/encoder\")\n",
    "\n",
    "# Label maps\n",
    "with open(f\"{BASE_DIR}/lob_label_map.json\") as f:\n",
    "    lob_label_to_id = json.load(f)\n",
    "\n",
    "with open(f\"{BASE_DIR}/coverage_label_maps.json\") as f:\n",
    "    coverage_label_to_id_by_lob = json.load(f)\n",
    "\n",
    "# Invert maps\n",
    "lob_id_to_label = {v: k for k, v in lob_label_to_id.items()}\n",
    "coverage_id_to_label_by_lob = {\n",
    "    lob: {v: k for k, v in covs.items()}\n",
    "    for lob, covs in coverage_label_to_id_by_lob.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cceef5",
   "metadata": {},
   "source": [
    "### Rebuild and load the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55fdcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lob = len(lob_id_to_label)\n",
    "num_cov = max(len(v) for v in coverage_id_to_label_by_lob.values())\n",
    "\n",
    "model = DebertaHierarchicalClassifier(\n",
    "    encoder=encoder,\n",
    "    num_lob=num_lob,\n",
    "    num_cov=num_cov\n",
    ")\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(f\"{BASE_DIR}/model/model_full.pt\", map_location=device)\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7ece89",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f8836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_claim(text, model, tokenizer,\n",
    "                  lob_id_to_label, coverage_id_to_label_by_lob):\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        lob_logits, cov_logits = model(input_ids, attention_mask)\n",
    "\n",
    "    # LOB\n",
    "    lob_probs = F.softmax(lob_logits, dim=1)\n",
    "    lob_id = torch.argmax(lob_probs, dim=1).item()\n",
    "    lob_label = lob_id_to_label[lob_id]\n",
    "    lob_conf = lob_probs[0, lob_id].item()\n",
    "\n",
    "    # Coverage \n",
    "    cov_probs = F.softmax(cov_logits, dim=1)\n",
    "    valid_covs = coverage_id_to_label_by_lob[lob_label]\n",
    "\n",
    "    cov_id = max(\n",
    "        valid_covs.keys(),\n",
    "        key=lambda i: cov_probs[0, i].item()\n",
    "    )\n",
    "\n",
    "    cov_label = valid_covs[cov_id]\n",
    "    cov_conf = cov_probs[0, cov_id].item()\n",
    "\n",
    "    return {\n",
    "        \"line_of_business\": lob_label,\n",
    "        \"lob_confidence\": round(lob_conf, 3),\n",
    "        \"coverage_type\": cov_label,\n",
    "        \"coverage_confidence\": round(cov_conf, 3)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87ba727",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e48701be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'line_of_business': 'wc', 'lob_confidence': 0.998, 'coverage_type': 'wc_Disability_Wage_Replacement_Benefits', 'coverage_confidence': 0.519}\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"\"\"\n",
    "EE [EMPLOYEE] ([ORG] [[ORG]], [ORG] [[ORG]], ph ([PHONE]) sustained slip/trip/fall injury to thoracic @ [P[ORG]SON] 9031 [P[ORG]SON], [GPE], OH 44308 around 07:15. Tx at [ORG]. light duty requested. Drug screen per policy. results neg. [PERSON]: 2729 [PERSON], [GPE], WI 53703. DOI recorded. [ORG] noted. IME scheduled. MMI not reached. [ORG] initiated. waiting wage records.\n",
    "\"\"\"\n",
    "\n",
    "result = predict_claim(\n",
    "    text=sample_text,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    lob_id_to_label=lob_id_to_label,\n",
    "    coverage_id_to_label_by_lob=coverage_id_to_label_by_lob\n",
    ")\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
